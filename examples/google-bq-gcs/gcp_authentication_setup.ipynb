{"cells":[{"cell_type":"markdown","source":["# GCP Authentication Setup\nThis Notebook outlines the steps required to configure your clusters"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fd14365-5563-4984-9ca7-ea5f4331367a"}}},{"cell_type":"markdown","source":["**Steps**\n\n1. Identify\n  * Google Cloud project that will be the **querying** project. This is the project that will be billed for the queries run against BigQuery\n  * Google Cloud project that will be the **data source**. This is the project that houses the BigQuery datasets / tables to be queried\n  * (If requiring WRITEs to BQ): Identify a Google Cloud Storage (GCS) bucket to hold temporary Parquet files before loading them into BigQuery \n2. (If requiring WRITEs to BQ): Provision a GCS bucket to hold temporary Parquet files before loading them into BigQuery ([sample code](01_create_gcs_bucket.sh))\n3. Google Cloud service account ([sample code](02_provision_gcp_service_account.sh))\n  * Create service account in querying project\n  * Provide service account with appropriate permissions to querying project\n  * Provide service account with appropriate permissions to BQ project\n  * (If requiring WRITEs to BQ): Provide service account with appropriate permissions to temporary storage bucket\n4. Register service account credentials with Databricks Secrets ([sample code](03_register_gcp_secrets.sh))\n5. Configure clusters"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c4c0d5a-4d7b-40f2-b2b5-193af5b557f9"}}},{"cell_type":"markdown","source":["## Cluster configuration\n\n- Let's assume our service account name is `databricks-reader@vinoaj-querying-source.iam.gserviceaccount.com`\n- If you have followed the above code examples, your secrets will be in Databricks Secrets with:\n  - Scope: `cloud-credentials`\n  - Key: `databricks-reader@vinoaj-querying-source.iam.gserviceaccount.com*`\n- Add the following configuration to the cluster's Spark config settings\n```\n# For BQ READ-ONLY\ncredentials {{secrets/cloud-credentials/databricks-reader@vinoaj-querying-source.iam.gserviceaccount.com}}\n\n# Include the below only if you require BQ WRITE and/or GCS READ+WRITE\nspark.hadoop.google.cloud.auth.service.account.enable true\nspark.hadoop.fs.gs.auth.service.account.email databricks-reader@vinoaj-querying-source.iam.gserviceaccount.com\nspark.hadoop.fs.gs.project.id vinoaj-querying-source\nspark.hadoop.fs.gs.auth.service.account.private.key {{secrets/cloud-credentials/databricks-reader@vinoaj-querying-source.iam.gserviceaccount.com-private-key}}\nspark.hadoop.fs.gs.auth.service.account.private.key.id {{secrets/cloud-credentials/databricks-reader@vinoaj-querying-source.iam.gserviceaccount.com-private-key-id}}\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5074b339-76a1-4013-b629-f76e8941984c"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"gcp_authentication_setup","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":145370659986097}},"nbformat":4,"nbformat_minor":0}
